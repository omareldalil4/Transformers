{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLPDL29PpyU68hUbBdJ7oF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omareldalil4/Transformers/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTV6rq2fmZ-r",
        "outputId": "1c801e11-42b4-4b73-b546-c520b4dae0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['What', 'are', 'the', 'symptoms', 'of', 'diabetes']\n",
            "\n",
            "Embeddings:\n",
            "tensor([[-1.6928, -0.8235, -1.6247, -0.7604],\n",
            "        [-0.7562,  1.2801,  0.0201,  0.8880],\n",
            "        [ 1.2130,  1.1126,  1.3241,  0.7374],\n",
            "        [-0.5092,  1.1380, -2.3743,  0.5405],\n",
            "        [ 0.0657,  1.1266, -0.8109,  0.4358],\n",
            "        [-0.1330,  1.1831, -0.6830, -0.3501]])\n",
            "\n",
            "Positional Encodings:\n",
            "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  9.9995e-01,  1.0000e-04,  1.0000e+00],\n",
            "        [ 9.0930e-01,  9.9980e-01,  2.0000e-04,  1.0000e+00],\n",
            "        [ 1.4112e-01,  9.9955e-01,  3.0000e-04,  1.0000e+00],\n",
            "        [-7.5680e-01,  9.9920e-01,  4.0000e-04,  1.0000e+00],\n",
            "        [-9.5892e-01,  9.9875e-01,  5.0000e-04,  1.0000e+00]])\n",
            "\n",
            "Input with Positional Encoding (X):\n",
            "tensor([[-1.6928,  0.1765, -1.6247,  0.2396],\n",
            "        [ 0.0853,  2.2801,  0.0202,  1.8880],\n",
            "        [ 2.1223,  2.1124,  1.3243,  1.7374],\n",
            "        [-0.3681,  2.1375, -2.3740,  1.5405],\n",
            "        [-0.6911,  2.1258, -0.8105,  1.4358],\n",
            "        [-1.0919,  2.1818, -0.6825,  0.6499]])\n",
            "\n",
            "Weight Matrices:\n",
            "W_Q:\n",
            "tensor([[-0.6109,  1.7212, -0.5105,  0.4610],\n",
            "        [-0.3949,  0.5318, -1.0478,  0.7717],\n",
            "        [ 1.2190,  1.7817,  0.4472,  0.3051],\n",
            "        [-0.6410, -0.0705,  0.2813, -0.1124]])\n",
            "W_K:\n",
            "tensor([[-0.4290, -1.5193,  0.3217,  1.0406],\n",
            "        [ 0.0163, -0.7703,  0.1551,  0.1904],\n",
            "        [-1.3337, -0.3773, -2.5691, -0.0974],\n",
            "        [ 0.0435, -0.1214, -0.5485, -0.3874]])\n",
            "W_V:\n",
            "tensor([[ 0.3826,  0.0044, -0.5862, -2.0893],\n",
            "        [-0.1567,  0.2710, -0.5073,  0.6079],\n",
            "        [ 0.3449,  1.4648,  0.2072, -0.0643],\n",
            "        [ 0.8823,  0.4665,  0.1036, -0.5341]])\n",
            "\n",
            "Query Matrix (Q):\n",
            "tensor([[-1.1696, -5.7315,  0.0202, -1.1669],\n",
            "        [-2.1380,  1.2623, -1.8926,  1.5928],\n",
            "        [-1.6299,  7.0134, -2.2160,  2.8173],\n",
            "        [-4.5004, -3.8352, -2.6800,  0.5823],\n",
            "        [-2.3256, -1.6043, -1.8332,  0.9131],\n",
            "        [-1.4430, -1.9810, -1.8511,  0.8990]])\n",
            "Key Matrix (K):\n",
            "tensor([[ 2.9064,  3.0199,  3.5254, -1.6626],\n",
            "        [ 0.0558, -2.1228, -0.7064, -0.2105],\n",
            "        [-2.5666, -5.5622, -3.3450,  1.8087],\n",
            "        [ 3.4261, -0.3785,  5.4671, -0.3417],\n",
            "        [ 1.4746, -0.4560,  1.4020, -0.7917],\n",
            "        [ 1.4425,  0.1570,  1.3840, -0.9062]])\n",
            "Value Matrix (V):\n",
            "tensor([[-1.0243, -2.2277,  0.5910,  3.6206],\n",
            "        [ 1.3480,  1.5287, -1.0069,  0.1983],\n",
            "        [ 2.4705,  3.3322, -1.8612, -4.1630],\n",
            "        [ 0.0645, -2.1812, -1.2008,  1.3984],\n",
            "        [ 0.3897,  0.0557, -0.6924,  2.0214],\n",
            "        [-0.4217, -0.1100, -0.5408,  3.3045]])\n",
            "\n",
            "Raw Attention Scores:\n",
            "tensor([[ -9.3484,   6.1665,  16.3519,  -0.6645,   0.9205,  -0.7508],\n",
            "        [ -5.8611,  -0.8986,   3.8389,  -9.3470,  -3.8214,  -3.4744],\n",
            "        [  1.9732,  -7.0034, -11.1594, -10.6583,  -5.4696,  -3.4352],\n",
            "        [-17.5391,   4.8304,  21.4504, -14.4092,  -4.5529,  -5.6655],\n",
            "        [ -9.7923,   2.1893,  11.3378,  -8.8473,  -2.9954,  -3.4856],\n",
            "        [ -9.0985,   2.6216,  11.2702,  -7.3107,  -2.2657,  -2.8846]])\n",
            "\n",
            "Attention Weights (after softmax):\n",
            "tensor([[6.8943e-12, 3.7715e-05, 9.9996e-01, 4.0726e-08, 1.9872e-07, 3.7359e-08],\n",
            "        [6.0683e-05, 8.6742e-03, 9.9014e-01, 1.8584e-06, 4.6653e-04, 6.6006e-04],\n",
            "        [9.9483e-01, 1.2569e-04, 1.9695e-06, 3.2507e-06, 5.8264e-04, 4.4557e-03],\n",
            "        [1.1671e-17, 6.0542e-08, 1.0000e+00, 2.6693e-16, 5.0923e-12, 1.6739e-12],\n",
            "        [6.6570e-10, 1.0637e-04, 9.9989e-01, 1.7127e-09, 5.9585e-07, 3.6496e-07],\n",
            "        [1.4253e-09, 1.7535e-04, 9.9982e-01, 8.5178e-09, 1.3223e-06, 7.1216e-07]])\n",
            "\n",
            "Output:\n",
            "tensor([[ 2.4705,  3.3321, -1.8612, -4.1628],\n",
            "        [ 2.4577,  3.3124, -1.8523, -4.1168],\n",
            "        [-1.0205, -2.2165,  0.5850,  3.6178],\n",
            "        [ 2.4705,  3.3322, -1.8612, -4.1630],\n",
            "        [ 2.4704,  3.3320, -1.8612, -4.1625],\n",
            "        [ 2.4703,  3.3319, -1.8611, -4.1622]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def self_attention(input_sentence):\n",
        "    \"\"\"Compute self-attention for a given input sentence\"\"\"\n",
        "\n",
        "    tokens = input_sentence.split()\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    embedding_dim = 4\n",
        "    vocab_size = len(tokens)\n",
        "\n",
        "\n",
        "    embeddings = torch.randn(len(tokens), embedding_dim)\n",
        "    print(f\"\\nEmbeddings:\\n{embeddings}\")\n",
        "\n",
        "\n",
        "    positions = torch.arange(len(tokens)).unsqueeze(1)\n",
        "    position_enc = torch.zeros(len(tokens), embedding_dim)\n",
        "\n",
        "    for pos in range(len(tokens)):\n",
        "        for i in range(0, embedding_dim, 2):\n",
        "            position_enc[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embedding_dim)))\n",
        "            if i+1 < embedding_dim:\n",
        "                position_enc[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1))/embedding_dim)))\n",
        "\n",
        "    print(f\"\\nPositional Encodings:\\n{position_enc}\")\n",
        "\n",
        "    X = embeddings + position_enc\n",
        "    print(f\"\\nInput with Positional Encoding (X):\\n{X}\")\n",
        "\n",
        "\n",
        "    d_k = embedding_dim\n",
        "    W_Q = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_K = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_V = torch.randn(embedding_dim, embedding_dim)\n",
        "\n",
        "    print(f\"\\nWeight Matrices:\")\n",
        "    print(f\"W_Q:\\n{W_Q}\")\n",
        "    print(f\"W_K:\\n{W_K}\")\n",
        "    print(f\"W_V:\\n{W_V}\")\n",
        "\n",
        "\n",
        "    Q = torch.matmul(X, W_Q)\n",
        "    K = torch.matmul(X, W_K)\n",
        "    V = torch.matmul(X, W_V)\n",
        "\n",
        "    print(f\"\\nQuery Matrix (Q):\\n{Q}\")\n",
        "    print(f\"Key Matrix (K):\\n{K}\")\n",
        "    print(f\"Value Matrix (V):\\n{V}\")\n",
        "\n",
        "\n",
        "    attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    print(f\"\\nRaw Attention Scores:\\n{attention_scores}\")\n",
        "\n",
        "\n",
        "    attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "    print(f\"\\nAttention Weights (after softmax):\\n{attention_weights}\")\n",
        "\n",
        "\n",
        "    output = torch.matmul(attention_weights, V)\n",
        "    print(f\"\\nOutput:\\n{output}\")\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "input_sentence = \"What are the symptoms of diabetes\"\n",
        "output, attn_weights = self_attention(input_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dE5KJLIEmcd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}